title: CH9虚拟内存
author: Jiahao Wu
categories: 深入理解计算机系统
date: 2021-01-14 15:38:41
tags:
---
# 虚拟内存（Virtual Memory）

虚拟内存是硬件异常、硬件地址翻译、主存、磁盘文件和内核软件的完美交互，它为每个进程提供了一个大的、一致的和私有的地址空间。它有三个重要的能力：  
1. 它将主存看成是一个存储在磁盘上的地址空间的高速缓存，在主存中只保存活动区域，并根据需要在主存和磁盘之间来回传送数据，通过这种方式，它高效地使用了主存。  
2. 他为每个进程提供了一致的地址空间，它高效地使用了主存。  
3. 它保护了每个进程的地址空间不被其他进程破坏。  

## 物理和虚拟寻址

使用虚拟寻址，CPU通过生成一个虚拟地址来访问主存（被组织成一个由M个连续字节大小的单元组成的数组，每个字节都有唯一的物理地址），这个虚拟地址在被送到内存之前，先转换成适当的物理地址。地址翻译需要CPU硬件和操作系统之间的紧密合作。CPU芯片上叫做内存管理单元（Memory Management Unit，MMU）的专用硬件，利用存放在主存中的查询表来动态翻译。

## 地址空间

虚拟地址空间：${0,1,2,...,N-1}$，$N=2^n$。  
物理地址空间：${0,1,2,...,M-1}$，M不一定要素2的幂。

## 虚拟内存作为缓存的工具

磁盘上的数据被分割为块，作为主存和磁盘之间的传输单元。VM系统通过将虚拟内存分割为称为虚拟页的大小固定的块来处理这个问题，每个虚拟页大小为$P=2^p$字节。类似地，物理内存被分割为物理页，大小也为P字节（物理页被称为页帧）。  
在任何时刻，虚拟页吗被分为三个不相交的子集：  
- 为分配的：还未分配（或者创建）的页。  
- 缓存的：已缓存在物理内存中的已分配页。  
- 未缓存的：未缓存在物理内存中的已分配页。  

### DRAM缓存的组织结构

由于磁盘访问要比DRAM慢太多，所以DRAM缓存不命中比起SRAM缓存（L1、L2、L3）要昂贵得多。

### 页表

不命中->系统判定这个虚拟页在磁盘哪个位置，并将虚拟页复制到DRAM中，替换牺牲页。  
页表：虚拟页->物理页。  
页表实际上是页表条目（Page Table Entry，PTE）的数组，虚拟地址空间中的每个页在页表中一个固定偏移量处都有一个PTE，每个PTE都由一个有效位和一个n位地址字段组成。有效位表明该虚拟页是否被缓存在DRAM中。如果有效，地址字段是指向该虚拟页在DRAM中相应的物理页的起始位置；如果无效，那么一个空地址表明这个虚拟页还未分配，如果地址非空就是已分配但未被保存，地址指向虚拟页在磁盘上的起始位置。  

### 页命中

地址翻译硬件将虚拟地址作为一个索引来定位PTE->如果设置了有效位，则利用PTE中的物理内存地址构造出这个字的物理地址。

### 缺页

DRAM缓存不命中称为缺页（page fault）。
未命中则从磁盘复制到内存中的牺牲页中（牺牲页如果修改过则写回磁盘）。
在磁盘和内存之间传送页的活动叫做交换（swapping）或者页面调度（paging）。页从磁盘换入DRAM和从DRAM换出磁盘。

### 分配页面

例如，调用malloc，在磁盘上创建空间并且更新页表上该条目的（能够分配页面必然有剩余虚拟内存可分配）地址。

### 又是局部性救了我们

如果工作集的大小超出了物理内存的大小，那么程序将处于一种不信的状态，叫做抖动（thrashing），这时页面将不断地换进换出。

## 虚拟内存作为内存管理工具

- 简化链接：没搞太懂  
- 简化加载：没搞太懂  
- 简化共享：不同虚拟页映射到同一物理页来实现共享。  
- 简化内存分配  

## 虚拟内存作为内存保护的工具

通过在PTE上添加一些额外的许可位来控制对一个虚拟页面内容的访问十分简单。比如：
- SUP：是否进程必须运行在内核模式才能访问该页。  
- READ：控制读访问  
- WRITE：控制写访问  

## 地址翻译

如果违反了这些许可条件，那么CPU就会触发一般保护故障，将控制传递给内核中的异常处理程序。Linux shell一般将这种异常报告为“段错误（segmental fault）”。

## 地址翻译

$N=2^n$：虚拟地址空间中的地址数量
$M=2^m$：物理地址空间中的地址数量
$P=2^p$：页的大小
页表基址寄存器（Page Table Register，PTBR）指向当前页表。n位的虚拟地址包含两部分：一个p位的虚拟页面偏移（Virtual Page Offset，VPO）和一个（n-p）位的虚拟页号（VirtualPage Number，VPN）。MMU利用页表基址寄存器和VPN找到对应的PTE，然后将页表条目中的物理页号（PPN，m-p位）和虚拟地址中的虚拟页面偏移串联期来就得到相应的物理地址。注：物理页面和虚拟页面的页面偏移是一样的。

### 结合高速换粗和虚拟内存

### 利用TLB加速地址翻译

每次产生一个虚拟地址，MMU就必须查阅一个PTE（代价很大），以便将虚拟地址翻译为物理地址。如果PTE碰巧在L1中，那么开销就下降很多。然而，许多系统都试图消除即使是这样的开销，它们在MMU中包括了一个关于PTE的小的缓存，称为翻译后备缓冲器（TranslationLookaside Buffer，TLB）。  
TLB（TLB索引+TLB标记+PTE）是一个小的、虚拟寻址的缓存，其每一行都保存者一个由单个PTE组成的块，如果保存$T=2^t$个组，那么TLB索引由虚拟页号的t个最低位组成的，而TLB标记由VPN中剩余的位组成。TLB通常有高度的相联度。TLB命中的步骤：
1. CPU产生一个虚拟地址。  
2. MMU从TLB中取出相应的PTE。  
3. MMU将这个虚拟地址翻译成一个物理地址，并且将它发送到高速缓存/主存。  
4. 高速缓存/主存将所请求的数据字返回给CPU。  

当TLB不命中时，MMU必须从L1缓存中取出相应的PTE，新取出的PTE存放在TLB中，可能会覆盖一个已经存在的条目。  

### 多级页表

如果一级页表的一个PTE是空的，那么相应的二级页表就根本不会存在。这代表一种巨大的节约。 
对于k级别页表层次结构的地址翻译：  
虚拟地址：$VPN_1|VPN_2|...|VPN_k|VPO$  
一级页表,$VPN_1$->二级页表,$VPN_2$->...->k级页表$VPN_k$->$PPN$,$PPO$，$PPO==VPO$，物理页面偏移量==虚拟页面偏移量。  

### 综合：端到端的地址翻译  

虚拟地址：VPN（虚拟页码）+VPO（虚拟页偏移）  
VPN：TLBT（TLB标记）+TLBI（TLB索引）  
MMU从虚拟地址中抽取VPN，并检查TLB，看它是否因为前面某个内存引用缓存了VPN的条目的一个副本。TLB从VPN中抽取TLB索引，和TLB标记，检查TLBI组中是否有匹配，若存在匹配项，则命中，然后将缓存的PPN返回给MMU。
如果TLB不命中，那么MMU就需要从主存中取出相应的PTE（页表条目，存放在物理内存中）。将PTE中的PPN和来自虚拟地址的VPO连接起来，这就形成了物理地址。

## 案例研究：Intel Core i7/Linux内存系统

处理器：四个核、一个大的所有核共享的L3高速缓存，以及一个DRR3内存控制器。每个核包含一个层次结构的TLB、一个层次结构的数据和指令高速缓存，以及一组快速到店链路，这种链路基于QuickPath技术，是为了让一个核与其他核核外部I/O桥直接通信。TLB是虚拟寻址的，是四路组相联的。L1、L2、L3高速缓存是物理寻址的，块大小为64字节。L1和L2是8路相联的，而L3是16路相联的。

### Core i7 地址翻译

Core i7使用四级页表翻译。  
物理页表要求4KB对齐。  
页表条目PTE：  
位  
- 0：P（子页表是否在内存中存在）  
- 1：R/W（对于所有可访问页，只读或者读写访问权限）  
- 2：U/S（对于所有可访问页，用户或者超级用户（内核）模式访问权限）  
- 3：WT（子页表直写或者写回缓存策略）  
- 4：CD（能/不能缓存子页表）  
- 5：A（引用位，由MMU在读和写时设置，由软件清除）  
- 7：PS（页大小为4KB或4MB（只对第一层PTE定义））  
- 12-51：Base addr（子页表的物理基地址的最高40位）  
- 63：XD（能/不能从这个PTE可访问的所有页中取指令）  
注：还有第四级页表条目格式：  
- 0：P（子页表是否在内存中存在，如果P为0，则剩余63位操作系统可用）  
- 1：R/W（对于所有可访问页，只读或者读写访问权限）  
- 2：U/S（对于所有可访问页，用户或者超级用户（内核）模式访问权限）  
- 3：WT（子页表直写或者写回缓存策略）  
- 4：CD（能/不能缓存子页表）  
- 5：A（引用位，由MMU在读和写时设置，由软件清除）  
- 6：D（修改位，由MMU在读和写时设置，由软件清除）  
- 7：0  
- 8：G（全局页，在任务切换时，不从TLB驱逐出去）  
- 12-51：Base addr（子页表的物理基地址的最高40位）  
- 63：XD（能/不能从这个子页中取指令）  
引用位：每次访问，MMU都会设置A位，称为引用位，内核可以利用引用位来设计页替换算法。  
修改位：告诉内核替换页之前是否必须写回牺牲页。  

### 9.7.2 Linux虚拟内存系统

1. Linux虚拟内存区域  
区域的概念；每个存在的虚拟页面都必然属于某个区域；这允许虚拟地址空间有间隙。  
内核为系统进程维护一个单独的任务结构，这中的元素包含或者指向内核运行该进程所需要的所有信息（例如PID、指向用户栈的指针，可执行目标文件的名字，以及程序计数器）。  
2. Linux缺页异常处理   
MMU视图翻译A时触发一个缺页，这个异常导致控制转移到内核的缺页处理程序，随后执行如下步骤：  
1）虚拟地址A时合法的吗？（即A是否在某个区域结构定义的区域内）  
2）试图进行内存访问是否合法？进程是否有读、写或者执行这个区域内页面的权限。  
3）内核知道这个缺页是由于对合法的虚拟地址进行合法的操作造成的。然后，选择一个牺牲页面（如果修改过，写回），换入新的页面并更新页表，当缺页处理程序返回时，CPU重新启动引起缺页的指令。  

## 内存映射

Linux将一个虚拟内存区域与一个磁盘上的对象关联起来，以初始化这个虚拟内存的内容，这个过程称为内存映射。  
1）Linux文件系统中的普通文件  
2）匿名文件  
3）交换文件  

### 再看共享对象

一个映射到共享对象的虚拟内存区域叫做共享区域，类似地，也有私有区域。  
私有对象使用一种叫做写时复制的巧妙技术被映射到虚拟内存中。举例：两个进程共享了一个对象同一个物理副本。对于每个映射私有对象的进程，相应的页表条目标记为只读，并在区域结构被标记为私有写时复制。只要没有进程试图写它自己的私有区域，它们就可以继续共享物理内存中对象的一个单独副本，然而只要有一个进程试图写私有区域内的某个页面，那么这个写操作会触发一个保护故障。当故障处理程序注意到保护异常是由于进程试图写私有的写时复制区域中的一个页面而引起的，它就会在物理内存中创建这个页面的一个新副本，更新页表条目指向这个新的副本，然后恢复这个页面的写权限。

### 再看fork函数

### 再看execve函数

一个execve调用：  
```execve("a.out",NULL,NULL)```
该函数加载并允许可执行目标程序a.out中的程序，用a.out程序有效替代了当前的程序。加载并允许a.out需要一下几个步骤：  

- 删除已存在的用户区域

- 映射私有区域

- 映射共享区域

- 设置程序计数器（PC）

### 使用mmap函数的用户级内存映射

mmap函数要求内核创建一个新的虚拟内存区域，并将指定的一各连续的片（chunk）映射到这个新的
区域。

## 动态内存分配

虽然可以使用低级的mmap和munmap函数来创建和删除虚拟内存区域，但是C程序员还会觉得当运行时需要额外的虚拟内存时，用动态内存分配器（dynamic memory allocator）更方便，也有更好的可以移植性。
动态内存分配器维护者一个进程的虚拟内存区域，称为堆（heap）。  
分配器将堆视为一组不同大小的块的集合来维护。每个块就是一个连续的虚拟内存片，要么是已分配的，要么是空闲的。  

1. 显示分配器（例如C语言的malloc函数）  
2. 隐式分配器（也叫做垃圾收集器，要求分配器检测一个已分配块何时不再被程序所使用）  

### malloc和free函数

```C
#include<stdlib.h>
void *malloc(size_t size);
```
malloc函数返回一个指针，指向为至少size字节的内存块，这个块会为可能包含在这个块内的任何数据对象型做对齐。在32位模式中，地址总是8的倍数，在64位模式中地址总是16的倍数。  
如果malloc遇到问题（例如要求的内存块比可用的虚拟内存还大），就返回NULL，并设置errno。如果想要改变一个已分配块的大小，可以使用realloc函数。

### 分配器的要求和目标

1. 处理任意请求序列。一个应用可以有任意的分配请求序列何释放请求序列  
2. 立即响应请求  
3. 只使用堆  
4. 对齐块（对齐要求）    
一个分配请求的最糟糕运行时间与空闲块的数量成线性关系，而一个释放请求的运行时间是一个常数。  
一个系统中被所有进程分配的虚拟内存的全部数量是受磁盘上交换空间的数量限制的。

### 碎片

内部碎片何外部碎片。  
1. 内部碎片  
实际中为了满足对齐条件，分配器可能增加块的大小。  
2. 外部碎片  
当空闲内存合起来满足一个分配请求，但是没有一个单独的空闲块足够来满足这个请求，那么如果不向内核请求额外的虚拟内存就无法满足这个请求。  
分配器通常采用启发式策略来试图维持少量的大空闲块。  

### 实现问题

### 隐式空闲链表

优点是简单，缺点是任何操作的开销都要对空闲链表进行搜索。

### 放置已分配的块

三种放置策略：首次适配、下一次适配、最佳适配

### 分割空闲块

如果放置策略趋向于产生好的匹配，那么额外的内部碎片也是可以接受的。  
如果匹配不太好，那么分配器通常会把这个空闲块分割为两部分。第一部分变成分配块，而剩下的变成一个新的空闲块。  

### 获取额外的内存

### 合并内存块

假设一个对4字（16字节）有效载荷的请求，但是只有两个相邻的有效载荷为3字的空闲块，这种现象叫做假碎片。为了解决假碎片问题，任何实际的分配器都必须合并相邻的空闲块，这个过程称为合并。这就出现了一个重要的策略决定，那就是何视执行合并。分配器可以选择立即合并（也就是在每次一个块被释放时，就合并所有相邻的块），或者它也可以选择推迟合并（也就是等到某个稍晚的时候再合并空闲块，例如可以等到某个分配请求失败，再扫描整个堆，合并所有空闲块）。立即合并简单明了，但会产生某种形式的抖动（频繁的合并和分割），快速分配器通常会选择某种形式的推迟合并。

### 带边界标记的合并

头部、脚部，两者一样，各占一字。
头部可以让前面的块确定后继块的范围，脚部可以让后面的块确定前面块的范围。为了节省空间，已分配块没有脚部。

### 综合：实现一个简单的分配器

跳过，之后再看。

### 显示空闲链表

可以将堆组织成一个双向空闲链表，每个空闲块中，都包含一个pred（前驱）、succ（后继）指针。  
使用双向链表而不是隐式空闲链表，使首次适配的分配时间从块数量的线性时间降低到空闲块数量的线性时间。不过释放一个块的时间可以是线性的也可以是常数，这取决于我们所选择的空闲链表中块的排序策略。
一种方法是：LIFO（先进后出，将新释放的块放置在链表的开始处，这样子释放将是常数时间，如果使用了边界标记，合并也是常数时间）  
另一种方法是按地址顺序维护链表，其中链表中每个块的地址都小于它的后继的地址。在这种情况下，释放一个块需要线性时间的搜索来定位合适的前驱。但是这相对于LIFO排序有更高的内存利用率，接近最佳适配的利用率。

### 分离的空闲链表

一种流行的减少分配时间的方法是分离存储，维护多个空闲链表，其中每个链表中的块有大致相等的大小。一般的思路是将所有可能的块大小分成一些等价类，也叫做大小类。有很多种方式来定义大小类。例如根据2的幂：
{1},{2},{3，4},{5~8},...,{1025~2048},{2049~4096},{4097~$\infin$}  
1. 简单分离存储  
使用简单分离存储，每个大小类的空闲链表包含大小相等的块，每个块的大小就算这个大小类中的最大元素的大小。  
优点：释放和分配块，都是常数时间操作。而且每个片中都是大小相等的块，不分割，不合并。显著的缺点是：很容易造成内部碎片和外部碎片。  
2. 分离适配  
C标准库中的malloc包就是采用这种方法。这种方法既快速，对内存的使用也很有效率。搜索时间减少了，因为搜索被限制在堆的某个部分，而不是整个堆。  
为了分配一个块，先确定请求的大小类，并且对适当的空闲链表做首次适配，查找一个合适的块，如果找到一个，那么就分割它，并将剩余的部分插入到适当的空闲链表中，如果找不到合适的块，那么就搜索下一个更大的大小类的空闲链表。如此重复知道找到一个合适的块。如果空闲链表中没有合适的块，那么就像操作系统请求额外堆内存，从这个新的堆内存中分配出一个块，将剩余部分放置在适当的大小类中。要释放一个块，我们执行合并，并将结果放置在相应的空闲链表中。  
3. 伙伴系统  
一种特殊的分离适配，为每个块大小$2^k$维护一个分离空闲链表。请求块大小，向上舍入到最近的2的幂，找到一可用的块大小为$2^j$，然后递归地分割这个块，直到j=k。当分割时每个剩下的半块被放置在相应的空闲链表中。  
优点：快速搜索和合并，可能导致显著的内部碎片。不过如果，块大小预知时2的幂，伙伴系统分配器就很有吸引力了。  

## 垃圾收集

垃圾收集器（garbage collector）是一种动态内存分配器，它自动释放程序不再需要的已分配块。这些块被称为垃圾。

### 垃圾收集器的基本知识

垃圾收集器将内存视为一张有向可达图，包含根节点（包含指向堆中的指针）和堆节点（对应于一个堆中的已分配块）。当存在一条从任意根结点出发并达到p的有向路径时，我们说p节点时可达的。不可达节点对应于垃圾。  
向ML和Java这样的语言能够维护可达图的一种精确表示，也因此能够回收所有垃圾。例如C/C++这样的语言通常不能维持可达图的精确表示，这样的收集器也叫做保守的垃圾收集器，每个可达块都被正确标记为可达了，但是某些不可达节点可能被错误标记为可达了。  
需要堆空间时：应用通常会调用malloc，如果malloc找不到一个合适的空闲块，那么它就调用垃圾收集器，希望能够回收一些垃圾到空闲链表。

### Mark&Sweep垃圾收集器

Mark&Sweep垃圾收集器通常由标记（Mark）和清除（sweep）阶段组成。  标记：标记出根节点的所有可达和已分配的后继。  
清除：释放每个未标记的已分配块。  
块头部中空闲的低位中的一位通常用来表示这个快是否被标记了。

### C程序的保守Mark&Sweep

C语言的Mark&Sweep收集器必须是保守的，其根本原因是C语言不会用类型信息来标记内存位置。因此像int或者float这样的标量可以伪装成指针。

## C程序中的常见的与内存相关的错误

### 间接引用坏指针

### 读未初始化的内存

### 允许栈缓冲区溢出

### 假设指针和它们指向的对象是相同大小的

### 造成错位错误

### 引用指针而不是它所指向的对象

### 误解指针运算

### 引用不存在的变量

### 引用空闲堆块中的数据

### 引起内存泄漏